{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-26T16:25:43.480314Z",
     "end_time": "2023-04-26T16:25:44.048134Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from src.myclassifier import MyClassifier\n",
    "from src.mymetrics import MyMetrics\n",
    "from src.ppi import PPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-26T16:25:45.130102Z",
     "end_time": "2023-04-26T16:25:45.143944Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_project_rootpath():\n",
    "    \"\"\"\n",
    "    获取项目根目录。此函数的能力体现在，不论当前module被import到任何位置，都可以正确获取项目根目录\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    path = os.path.realpath(os.curdir)\n",
    "    while True:\n",
    "        for subpath in os.listdir(path):\n",
    "            # PyCharm项目中，'.idea'是必然存在的，且名称唯一\n",
    "            if '.idea' in subpath:\n",
    "                return path\n",
    "        path = os.path.dirname(path)\n",
    "\n",
    "\n",
    "os.chdir(get_project_rootpath())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-26T16:25:46.252551Z",
     "end_time": "2023-04-26T16:25:46.254358Z"
    }
   },
   "outputs": [],
   "source": [
    "EMB_ROOT_PATH = 'data/emb/'\n",
    "PPI_PATH = 'data/network/PPI-Network.txt'\n",
    "DEEPWALK_EMB_ROOT_PATH = os.path.join(EMB_ROOT_PATH, 'deepwalk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-26T16:25:46.892416Z",
     "end_time": "2023-04-26T16:25:46.900678Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataloader(file_name, positive_gene: set, risklevel: dict):\n",
    "    # file_name: emb files\n",
    "    # positive_gene: 正例的gene\n",
    "    # risklevel 出现了多少次的gene为positive gene\n",
    "\n",
    "    data = file_name.strip('.emb').split('_')\n",
    "    param = {i[0]: i[1:] for i in data[1:]}\n",
    "\n",
    "    # 训练特征和label\n",
    "    file_path = os.path.join(DEEPWALK_EMB_ROOT_PATH, file_name)\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = [line.strip().split() for line in f.readlines()[1:]]\n",
    "    X = [line[1:] for line in data]\n",
    "    target = [1 if int(line[0]) in positive_gene else 0 for line in data]\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    target = np.asarray(target, dtype=int)\n",
    "\n",
    "    # 权重\n",
    "    class_weight = compute_class_weight(class_weight='balanced', classes=[0, 1], y=target)\n",
    "    sample_weights = [risklevel[int(line[0])] * class_weight[1]\n",
    "                      if int(line[0]) in positive_gene else class_weight[0] for line in data]\n",
    "    return param, X, target, sample_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:44:32.404841Z",
     "start_time": "2023-04-25T11:44:32.385312Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "GENECOUNT_PATH = 'data/genecount.xls'\n",
    "\n",
    "ppi = PPI(ppi_network_path=PPI_PATH, gene_count_path=GENECOUNT_PATH, k=6)\n",
    "datasets = os.listdir(DEEPWALK_EMB_ROOT_PATH)\n",
    "models = {}\n",
    "result_acc = {}\n",
    "result_f1 = {}\n",
    "result_auc = {}\n",
    "result_aupr = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    params, X, y, weight = dataloader(dataset, ppi.positive_id, ppi.risk_level)\n",
    "    X_train, X_test, y_train, y_test, weight_train, weights_test = train_test_split(X, y,\n",
    "                                                                                    weight,\n",
    "                                                                                    test_size=0.3)\n",
    "    classifier = MyClassifier()\n",
    "    classifier.train(X_train, y_train, weight=weight_train)\n",
    "    y_pred_dict = classifier.predict(X_test)\n",
    "    y_score_dict = classifier.predict_proba(X_test)\n",
    "\n",
    "    for clf_name, y_pred in y_pred_dict.items():\n",
    "        metric = MyMetrics(y_test, y_pred)\n",
    "        acc, f1, auc, aupr = metric.evaluate(y_test, y_pred, y_score_dict[clf_name])\n",
    "        result_acc[(clf_name, params['d'], params['l'], params['n'])] = acc\n",
    "        result_f1[(clf_name, params['d'], params['l'], params['n'])] = f1\n",
    "        result_auc[(clf_name, params['d'], params['l'], params['n'])] = auc\n",
    "        result_aupr[(clf_name, params['d'], params['l'], params['n'])] = aupr\n",
    "        # save the trained model\n",
    "\n",
    "    model_name = f\"{params['d']}_{params['l']}_{params['n']}_deepwalk\"\n",
    "    models[model_name] = classifier\n",
    "\n",
    "# save all models in a file\n",
    "with open(\"model/deepwalk_all_models.pkl\", \"wb\") as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "Finished.\n",
      "querying 1-1000...done.\n",
      "querying 1001-2000...done.\n",
      "querying 2001-3000...done.\n",
      "querying 3001-4000...done.\n",
      "querying 4001-5000...done.\n",
      "querying 5001-6000...done.\n",
      "querying 6001-7000...done.\n",
      "querying 7001-8000...done.\n",
      "querying 8001-9000...done.\n",
      "querying 9001-10000...done.\n",
      "querying 10001-11000...done.\n",
      "querying 11001-11703...done.\n",
      "Finished.\n",
      "Time taken for iteration 1: 21.437336206436157 seconds\n",
      "Time taken for iteration 2: 21.69511389732361 seconds\n",
      "Time taken for iteration 3: 21.91542077064514 seconds\n",
      "Time taken for iteration 4: 20.74600911140442 seconds\n",
      "Time taken for iteration 5: 21.54145312309265 seconds\n",
      "Time taken for iteration 6: 21.67549705505371 seconds\n",
      "Time taken for iteration 7: 25.806737184524536 seconds\n",
      "Time taken for iteration 8: 22.12010383605957 seconds\n",
      "Time taken for iteration 9: 21.22550392150879 seconds\n",
      "Time taken for iteration 10: 22.224627017974854 seconds\n",
      "Time taken for iteration 11: 22.129969835281372 seconds\n",
      "Time taken for iteration 12: 21.47024893760681 seconds\n",
      "Time taken for iteration 13: 21.563533782958984 seconds\n",
      "Time taken for iteration 14: 21.80266499519348 seconds\n",
      "Time taken for iteration 15: 21.504104137420654 seconds\n",
      "Time taken for iteration 16: 23.02326798439026 seconds\n",
      "Time taken for iteration 17: 21.785645961761475 seconds\n",
      "Time taken for iteration 18: 21.5030517578125 seconds\n",
      "Time taken for iteration 19: 78.71532702445984 seconds\n",
      "Time taken for iteration 20: 48.86790609359741 seconds\n",
      "Time taken for iteration 21: 47.898266077041626 seconds\n",
      "Time taken for iteration 22: 88.97567701339722 seconds\n",
      "Time taken for iteration 23: 53.51422119140625 seconds\n",
      "Time taken for iteration 24: 47.31575560569763 seconds\n",
      "Time taken for iteration 26: 35.45193600654602 seconds\n",
      "Time taken for iteration 27: 60.26939916610718 seconds\n",
      "Time taken for iteration 28: 34.21902108192444 seconds\n",
      "Time taken for iteration 29: 61.60065793991089 seconds\n",
      "Time taken for iteration 30: 34.956130266189575 seconds\n",
      "Time taken for iteration 31: 61.16517877578735 seconds\n",
      "Time taken for iteration 32: 62.33276081085205 seconds\n",
      "Time taken for iteration 33: 35.079025745391846 seconds\n",
      "Time taken for iteration 34: 60.285404205322266 seconds\n",
      "Time taken for iteration 35: 61.57359218597412 seconds\n",
      "Time taken for iteration 36: 35.39217686653137 seconds\n",
      "Time taken for iteration 37: 21.939218997955322 seconds\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# 加载所有模型和结果\n",
    "with open(\"model/deepwalk_all_models.pkl\", \"rb\") as f:\n",
    "    all_models = pickle.load(f)\n",
    "\n",
    "GENECOUNT_PATH = 'data/genecount.xls'\n",
    "\n",
    "ppi = PPI(ppi_network_path=PPI_PATH, gene_count_path=GENECOUNT_PATH, k=6)\n",
    "datasets = os.listdir(DEEPWALK_EMB_ROOT_PATH)\n",
    "models = {}\n",
    "result_acc = {}\n",
    "result_f1 = {}\n",
    "result_auc = {}\n",
    "result_aupr = {}\n",
    "step = 1\n",
    "for dataset in datasets:\n",
    "    start_time = time.time()\n",
    "    params, X, y, weight = dataloader(dataset, ppi.positive_id, ppi.risk_level)\n",
    "    X_train, X_test, y_train, y_test, weight_train, weights_test = train_test_split(X, y,\n",
    "                                                                                    weight,\n",
    "                                                                                    test_size=0.3)\n",
    "\n",
    "    for clf_name in ['svm', 'rf', 'nb']:\n",
    "        cur_model_name = f\"{clf_name}_{params['d']}_{params['l']}_{params['n']}_deepwalk\"\n",
    "    classifier = all_models[cur_model_name]\n",
    "    y_pred_dict = classifier.predict(X_test)\n",
    "    y_score_dict = classifier.predict_proba(X_test)\n",
    "    for clf_name, y_pred in y_pred_dict.items():\n",
    "        metric = MyMetrics(y_test, y_pred)\n",
    "        acc, f1, auc, aupr = metric.evaluate(y_test, y_pred, y_score_dict[clf_name])\n",
    "        result_acc[(clf_name, params['d'], params['l'], params['n'])] = acc\n",
    "        result_f1[(clf_name, params['d'], params['l'], params['n'])] = f1\n",
    "        result_auc[(clf_name, params['d'], params['l'], params['n'])] = auc\n",
    "        result_aupr[(clf_name, params['d'], params['l'], params['n'])] = aupr\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    print(f\"Time taken for iteration {step}: {time_taken} seconds\")\n",
    "    step += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T16:32:40.828736Z",
     "end_time": "2023-04-26T16:56:47.907686Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-26T16:57:33.453493Z",
     "end_time": "2023-04-26T16:57:33.479104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{128: 0.898886827458256,\n 256: 0.8676217961932248,\n 64: 0.9022710094138665,\n 512: 0.8581220366934653}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def observe_param_effect(result_dict, method, param):\n",
    "    def get_param_values(p):\n",
    "        values = set()\n",
    "        for key in result_dict.keys():\n",
    "            values.add(key[p])\n",
    "        return list(values)\n",
    "\n",
    "    def get_avg_param(k):\n",
    "        k_items = list(filter(lambda x: x[0][0] == method and x[0][1] == k, result_dict.items()))\n",
    "        k_values = [x[1] for x in k_items]\n",
    "\n",
    "        avg_k = sum(k_values) / len(k_values)\n",
    "        return avg_k\n",
    "\n",
    "    param_map = {\n",
    "        'dim': 1,\n",
    "        'length': 2,\n",
    "        'num': 3\n",
    "    }\n",
    "    return {int(k): get_avg_param(k) for k in get_param_values(param_map[param])}\n",
    "\n",
    "\n",
    "observe_param_effect(result_acc, 'svm', 'dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def result_plotting(performance_indicator):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    for k in performance_indicator.keys():\n",
    "        a, b, c = k\n",
    "        x.append(int(a))\n",
    "        y.append(int(b))\n",
    "        z.append(int(c))\n",
    "\n",
    "    # Creating figure\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax = plt.axes(projection=\"3d\")\n",
    "\n",
    "    # Add x, y gridlines\n",
    "    ax.grid(visible=True, color='grey',\n",
    "            linestyle='-.', linewidth=0.3,\n",
    "            alpha=0.2)\n",
    "\n",
    "    # Creating color map 设置配色图\n",
    "    my_cmap = plt.get_cmap('hsv')\n",
    "\n",
    "    # Creating plot\n",
    "    sctt = ax.scatter3D(x, y, z,\n",
    "                        alpha=0.8,\n",
    "                        c=list(performance_indicator.values()),\n",
    "                        cmap=my_cmap)\n",
    "\n",
    "    plt.title(\"simple 3D scatter plot\")\n",
    "\n",
    "    ax.set_xlabel('dim', fontweight='bold')\n",
    "    ax.set_ylabel('length', fontweight='bold')\n",
    "    ax.set_zlabel('num', fontweight='bold')\n",
    "    fig.colorbar(sctt, ax=ax, shrink=0.5, aspect=5)\n",
    "\n",
    "    # show plot\n",
    "    plt.show()\n",
    "\n",
    "# result_plotting(acc_nm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
